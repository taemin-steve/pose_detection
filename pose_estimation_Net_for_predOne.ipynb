{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, recall_score, precision_score\n",
    "from torch import optim\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DataFram\n",
    "\n",
    "###  - columns: review_img_path, product_img_path, Normalized x,y,z ,Ppresenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>landmark_x</th>\n",
       "      <th>landmark_y</th>\n",
       "      <th>landmark_z</th>\n",
       "      <th>landmark_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/review_img\\0_review_img\\O\\0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/review_img\\0_review_img\\O\\1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7430019378662109, 0.30140167474746704, 0.80...</td>\n",
       "      <td>[0.05356726050376892, 0.04893580079078674, 0.2...</td>\n",
       "      <td>[-0.041502147912979126, 0.029880573973059654, ...</td>\n",
       "      <td>[0.9962781071662903, 0.9993698000907898, 0.990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/review_img\\0_review_img\\O\\10.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/review_img\\0_review_img\\O\\100.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/review_img\\0_review_img\\O\\101.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46417</th>\n",
       "      <td>./data/review_img\\9_review_img\\X\\5.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46418</th>\n",
       "      <td>./data/review_img\\9_review_img\\X\\6.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5282172560691833, 0.3690560460090637, 0.617...</td>\n",
       "      <td>[0.17353519797325134, 0.23485377430915833, 0.2...</td>\n",
       "      <td>[-0.15574988722801208, -0.15539097785949707, -...</td>\n",
       "      <td>[0.9999688863754272, 0.9998100399971008, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46419</th>\n",
       "      <td>./data/review_img\\9_review_img\\X\\7.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5049400329589844, 0.43606045842170715, 0.62...</td>\n",
       "      <td>[0.21291744709014893, 0.23801586031913757, 0.2...</td>\n",
       "      <td>[-0.3643159866333008, 0.3272627294063568, -0.5...</td>\n",
       "      <td>[0.9999638795852661, 0.9995668530464172, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46420</th>\n",
       "      <td>./data/review_img\\9_review_img\\X\\8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6021363735198975, 0.43856194615364075, 0.59...</td>\n",
       "      <td>[0.08433413505554199, 0.045614272356033325, 0....</td>\n",
       "      <td>[-0.006123891565948725, -0.33828288316726685, ...</td>\n",
       "      <td>[0.9998842477798462, 0.9997095465660095, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46421</th>\n",
       "      <td>./data/review_img\\9_review_img\\X\\9.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5680345296859741, 0.4259580373764038, 0.610...</td>\n",
       "      <td>[0.3095270097255707, 0.31925976276397705, 0.42...</td>\n",
       "      <td>[-0.0046425494365394115, 0.12861797213554382, ...</td>\n",
       "      <td>[0.9998698234558105, 0.9991586208343506, 0.998...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46422 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_path  label   \n",
       "0        ./data/review_img\\0_review_img\\O\\0.jpg      0  \\\n",
       "1        ./data/review_img\\0_review_img\\O\\1.jpg      0   \n",
       "2       ./data/review_img\\0_review_img\\O\\10.jpg      0   \n",
       "3      ./data/review_img\\0_review_img\\O\\100.jpg      0   \n",
       "4      ./data/review_img\\0_review_img\\O\\101.jpg      0   \n",
       "...                                         ...    ...   \n",
       "46417    ./data/review_img\\9_review_img\\X\\5.jpg      1   \n",
       "46418    ./data/review_img\\9_review_img\\X\\6.jpg      1   \n",
       "46419    ./data/review_img\\9_review_img\\X\\7.jpg      1   \n",
       "46420    ./data/review_img\\9_review_img\\X\\8.jpg      1   \n",
       "46421    ./data/review_img\\9_review_img\\X\\9.jpg      1   \n",
       "\n",
       "                                              landmark_x   \n",
       "0                                                    NaN  \\\n",
       "1      [0.7430019378662109, 0.30140167474746704, 0.80...   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "46417                                                NaN   \n",
       "46418  [0.5282172560691833, 0.3690560460090637, 0.617...   \n",
       "46419  [0.5049400329589844, 0.43606045842170715, 0.62...   \n",
       "46420  [0.6021363735198975, 0.43856194615364075, 0.59...   \n",
       "46421  [0.5680345296859741, 0.4259580373764038, 0.610...   \n",
       "\n",
       "                                              landmark_y   \n",
       "0                                                    NaN  \\\n",
       "1      [0.05356726050376892, 0.04893580079078674, 0.2...   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "46417                                                NaN   \n",
       "46418  [0.17353519797325134, 0.23485377430915833, 0.2...   \n",
       "46419  [0.21291744709014893, 0.23801586031913757, 0.2...   \n",
       "46420  [0.08433413505554199, 0.045614272356033325, 0....   \n",
       "46421  [0.3095270097255707, 0.31925976276397705, 0.42...   \n",
       "\n",
       "                                              landmark_z   \n",
       "0                                                    NaN  \\\n",
       "1      [-0.041502147912979126, 0.029880573973059654, ...   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "46417                                                NaN   \n",
       "46418  [-0.15574988722801208, -0.15539097785949707, -...   \n",
       "46419  [-0.3643159866333008, 0.3272627294063568, -0.5...   \n",
       "46420  [-0.006123891565948725, -0.33828288316726685, ...   \n",
       "46421  [-0.0046425494365394115, 0.12861797213554382, ...   \n",
       "\n",
       "                                       landmark_presence  \n",
       "0                                                    NaN  \n",
       "1      [0.9962781071662903, 0.9993698000907898, 0.990...  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "46417                                                NaN  \n",
       "46418  [0.9999688863754272, 0.9998100399971008, 0.999...  \n",
       "46419  [0.9999638795852661, 0.9995668530464172, 0.999...  \n",
       "46420  [0.9998842477798462, 0.9997095465660095, 0.999...  \n",
       "46421  [0.9998698234558105, 0.9991586208343506, 0.998...  \n",
       "\n",
       "[46422 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./img_Pose.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['landmark_presence'][1][1:-1]\n",
    "list = [float(i.strip()) for i in df['landmark_presence'][1][1:-1].split(\",\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    42526\n",
       "1     3896\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    35675\n",
       "1     2287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = []\n",
    "# proper_review = glob.glob('./data/review_img/*/O/*')\n",
    "# proper_review = sorted(proper_review)\n",
    "\n",
    "# for _ in range(len(proper_review)):\n",
    "#     label.append(0)\n",
    "    \n",
    "# unfit_review = glob.glob('./data/review_img/*/X/*')\n",
    "# unfit_review = sorted(unfit_review)\n",
    "\n",
    "# for _ in range(len(unfit_review)):\n",
    "#     label.append(1)\n",
    "\n",
    "# image_path = proper_review + unfit_review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['img_path','label'])\n",
    "# df['img_path'] = image_path\n",
    "# df['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':1,\n",
    "    'LEARNING_RATE':3e-8,\n",
    "    # 'LEARNING_RATE':10,\n",
    "    'BATCH_SIZE':1,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Mediapipe model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='pose_landmarker.task')\n",
    "\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    num_poses = 22,\n",
    "    output_segmentation_masks=False)\n",
    "\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pose_landmarks_list:\n\u001b[1;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m save_x\u001b[39m.\u001b[39mappend([i\u001b[39m.\u001b[39mx \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m pose_landmarks_list[\u001b[39m0\u001b[39;49m][\u001b[39m11\u001b[39m:\u001b[39m33\u001b[39m]])\n\u001b[1;32m     29\u001b[0m save_y\u001b[39m.\u001b[39mappend([i\u001b[39m.\u001b[39my \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m pose_landmarks_list[\u001b[39m0\u001b[39m][\u001b[39m11\u001b[39m:\u001b[39m33\u001b[39m]])\n\u001b[1;32m     30\u001b[0m save_z\u001b[39m.\u001b[39mappend([i\u001b[39m.\u001b[39mz \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m pose_landmarks_list[\u001b[39m0\u001b[39m][\u001b[39m11\u001b[39m:\u001b[39m33\u001b[39m]])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "save_x = []\n",
    "save_y = []\n",
    "save_z = []\n",
    "save_presence = []\n",
    "\n",
    "# for i in tqdm(image_path):\n",
    "#     img = mp.Image.create_from_file(i)\n",
    "#     pose_landmarks_list = detector.detect(img).pose_landmarks\n",
    "    \n",
    "#     if not pose_landmarks_list:\n",
    "#         save_x.append(None)\n",
    "#         save_y.append(None)\n",
    "#         save_z.append(None)\n",
    "#         save_presence.append(None)\n",
    "#         continue\n",
    "        \n",
    "#     save_x.append([i.x for i in pose_landmarks_list[0][11:33]])\n",
    "#     save_y.append([i.y for i in pose_landmarks_list[0][11:33]])\n",
    "#     save_z.append([i.z for i in pose_landmarks_list[0][11:33]])\n",
    "#     save_presence.append([i.presence for i in pose_landmarks_list[0][11:33]])\n",
    "    \n",
    "img = mp.Image.create_from_file(\"person1.png\")\n",
    "pose_landmarks_list = detector.detect(img).pose_landmarks\n",
    "    \n",
    "if not pose_landmarks_list:\n",
    "    print('None')\n",
    "        \n",
    "save_x.append([i.x for i in pose_landmarks_list[0][11:33]])\n",
    "save_y.append([i.y for i in pose_landmarks_list[0][11:33]])\n",
    "save_z.append([i.z for i in pose_landmarks_list[0][11:33]])\n",
    "save_presence.append([i.presence for i in pose_landmarks_list[0][11:33]])\n",
    "df = pd.DataFrame(columns=['img_path','label'])\n",
    "\n",
    "df['img_path'] = None\n",
    "df['label'] = 0\n",
    "df['landmark_x'] = save_x\n",
    "df['landmark_y'] = save_y\n",
    "df['landmark_z'] = save_z\n",
    "df['landmark_presence'] = save_presence\n",
    "\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./img_Pose.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path ,landmark_x, landmark_y,\tlandmark_z,\tlandmark_presence, label):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        self.landmark_x = landmark_x\n",
    "        self.landmark_y = landmark_y\n",
    "        self.landmark_z= landmark_z\n",
    "        self.landmark_presence = landmark_presence\n",
    "        \n",
    "        \n",
    "        self.label = label\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # landmarkX = [float(i.strip()) for i in self.landmark_x[index][1:-1].split(\",\")]\n",
    "        # landmarkY = [float(i.strip()) for i in self.landmark_y[index][1:-1].split(\",\")]\n",
    "        # landmarkZ = [float(i.strip()) for i in self.landmark_z[index][1:-1].split(\",\")]\n",
    "        # landmarkPre = [float(i.strip()) for i in self.landmark_presence[index][1:-1].split(\",\")]\n",
    "        \n",
    "        \n",
    "        result = np.concatenate((self.landmark_x[index] , self.landmark_y[index] , self.landmark_z[index] , self.landmark_presence[index]), axis=0)\n",
    "        print(result)\n",
    "        \n",
    "        \n",
    "        # print(result.shape)\n",
    "        # print(type(result[0]))\n",
    "        return result, self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.landmark_x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset(train[\"img_path\"].values, train[\"landmark_x\"].values, train[\"landmark_y\"].values, train[\"landmark_z\"].values,train[\"landmark_presence\"].values, train[\"label\"].values)\n",
    "# train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(df[\"img_path\"].values, df[\"landmark_x\"].values, df[\"landmark_y\"].values, df[\"landmark_z\"].values,df[\"landmark_presence\"].values, df[\"label\"].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.classifier1 = nn.Linear(88, 20)\n",
    "        # self.classifier1 = nn.Linear(22, 2)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.classifier2 = nn.Linear(20, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classifier1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.classifier2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for landmark_list, labels in tqdm(iter(val_loader)):\n",
    "            \n",
    "            landmark_list = landmark_list.float().to(device)\n",
    "            \n",
    "            # labels = labels.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            pred = model(landmark_list)\n",
    "\n",
    "            # loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.detach().argmax(1).cpu().numpy().tolist()\n",
    "            # true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            # val_loss.append(loss.item())\n",
    "            # print(preds, true_labels)\n",
    "            # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "            \n",
    "        # _val_loss = np.mean(val_loss)\n",
    "        # _val_score_f1 = f1_score(true_labels, preds, average='weighted')\n",
    "        # _val_score_acc = accuracy_score(true_labels, preds)\n",
    "        # _val_score_recall = recall_score(true_labels, preds, average='macro')\n",
    "        # _val_score_precision = precision_score(true_labels, preds, average='macro')\n",
    "        # report = classification_report(true_labels, preds)\n",
    "        \n",
    "        # print(accuracy_score(true_labels, preds))\n",
    "        \n",
    "        \n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.NLLLoss(weight=torch.tensor([0.01, 0.99]), reduction=\"sum\").to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(0, CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        train_loss = []         \n",
    "                \n",
    "        label = validation(model, criterion, val_loader, device)\n",
    "        \n",
    "        # _train_loss = np.mean(train_loss)\n",
    "        # print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val accuracy score : [{_val_score_acc:.5f}] Val recall score : [{_val_score_recall:.5f}] Val f1 score : [{_val_score_f1:.5f}]')\n",
    "        # print(report)\n",
    "        \n",
    "        # if scheduler is not None:\n",
    "        #     scheduler.step(_val_score_recall)\n",
    "            \n",
    "        # if best_score > _val_score_recall:\n",
    "        #     best_score = _val_score_recall\n",
    "        #     best_model = model\n",
    "            # torch.save(best_model.state_dict(\"./Pose_Estimate.pt\"))\n",
    "            \n",
    "    return best_model , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel()\n",
    "model.load_state_dict(torch.load('./Pose_Estimate_new.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model, label = train(model, optimizer, None, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
