{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c7088231fa4276b09a68a0693fe119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올바른 이미지 입니다\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def Pose_Estimation(img_path):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    CFG = {\n",
    "        'EPOCHS':1,\n",
    "        'LEARNING_RATE':3e-8,\n",
    "        # 'LEARNING_RATE':10,\n",
    "        'BATCH_SIZE':1,\n",
    "        'SEED':41\n",
    "        }\n",
    "    base_options = python.BaseOptions(model_asset_path='pose_landmarker.task')\n",
    "\n",
    "    options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        num_poses = 22,\n",
    "        output_segmentation_masks=False)\n",
    "\n",
    "    detector = vision.PoseLandmarker.create_from_options(options)\n",
    "    \n",
    "    save_x = []\n",
    "    save_y = []\n",
    "    save_z = []\n",
    "    save_presence = []\n",
    "    \n",
    "        \n",
    "    img = mp.Image.create_from_file(img_path)\n",
    "    pose_landmarks_list = detector.detect(img).pose_landmarks\n",
    "        \n",
    "    if not pose_landmarks_list:\n",
    "        return \"전신 사진이어야 합니다!\"\n",
    "            \n",
    "    save_x.append([i.x for i in pose_landmarks_list[0][11:33]])\n",
    "    save_y.append([i.y for i in pose_landmarks_list[0][11:33]])\n",
    "    save_z.append([i.z for i in pose_landmarks_list[0][11:33]])\n",
    "    save_presence.append([i.presence for i in pose_landmarks_list[0][11:33]])\n",
    "    \n",
    "    df = pd.DataFrame(columns=['img_path','label'])\n",
    "    \n",
    "    df['img_path'] = None\n",
    "    df['label'] = 0\n",
    "    df['landmark_x'] = save_x\n",
    "    df['landmark_y'] = save_y\n",
    "    df['landmark_z'] = save_z\n",
    "    df['landmark_presence'] = save_presence\n",
    "    \n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, img_path ,landmark_x, landmark_y,\tlandmark_z,\tlandmark_presence, label):\n",
    "            self.img_path = img_path\n",
    "            self.landmark_x = landmark_x\n",
    "            self.landmark_y = landmark_y\n",
    "            self.landmark_z= landmark_z\n",
    "            self.landmark_presence = landmark_presence\n",
    "            self.label = label\n",
    "\n",
    "        def __getitem__(self,index):\n",
    "\n",
    "            result = np.concatenate((self.landmark_x[index] , self.landmark_y[index] , self.landmark_z[index] , self.landmark_presence[index]), axis=0)\n",
    "            return result, self.label[index]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.landmark_x )\n",
    "    \n",
    "    val_dataset = CustomDataset(df[\"img_path\"].values, df[\"landmark_x\"].values, df[\"landmark_y\"].values, df[\"landmark_z\"].values,df[\"landmark_presence\"].values, df[\"label\"].values)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    class BaseModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BaseModel, self).__init__()\n",
    "            self.classifier1 = nn.Linear(88, 20)\n",
    "            # self.classifier1 = nn.Linear(22, 2)\n",
    "            self.ReLU = nn.ReLU(inplace=True)\n",
    "            self.classifier2 = nn.Linear(20, 2)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.classifier1(x)\n",
    "            x = self.ReLU(x)\n",
    "            x = self.classifier2(x)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        \n",
    "    def validation(model, criterion, val_loader, device):\n",
    "        model.eval()\n",
    "        preds= []\n",
    "        with torch.no_grad():\n",
    "            for landmark_list, labels in tqdm(iter(val_loader)):\n",
    "                landmark_list = landmark_list.float().to(device)\n",
    "                pred = model(landmark_list)\n",
    "                preds += pred.detach().argmax(1).cpu().numpy().tolist()\n",
    "        return preds\n",
    "\n",
    "\n",
    "    def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "        model = model.to(device)\n",
    "        criterion = nn.NLLLoss(weight=torch.tensor([0.01, 0.99]), reduction=\"sum\").to(device)\n",
    "        best_model = None\n",
    "        for epoch in range(0, CFG['EPOCHS']):\n",
    "            model.train()\n",
    "            label = validation(model, criterion, val_loader, device)\n",
    "        return best_model , label\n",
    "    \n",
    "    model = BaseModel()\n",
    "    model.load_state_dict(torch.load('./Pose_Estimate_new.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "    infer_model, label = train(model, optimizer, None, val_loader, scheduler, device)\n",
    "    \n",
    "    if label[0] == 0:\n",
    "        return \"올바른 이미지 입니다\"\n",
    "    else:\n",
    "        return \"잘못된 이미지 입니다.\"\n",
    "\n",
    "print(Pose_Estimation('person2.png'))\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
